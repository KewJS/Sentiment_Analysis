{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, OrderedDict\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML, clear_output, display_html\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torchtext\n",
    "from datasets import Dataset\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from src.train import Train\n",
    "from src.train.ensemble import Model\n",
    "from src.train.bert import BertClassifier\n",
    "from src.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams[\"figure.figsize\"] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Train, Validation, Test Dataset of Google Play Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2>Book Reviews Sentiment Analysis</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"<h2>Book Reviews Sentiment Analysis</h2>\"))\n",
    "loading_section       = [\"Prepare Model Data\", \"Data Understanding\"]\n",
    "sections              = [\"Train\", \"Evaluation\"]\n",
    "conclusion_section    = [\"Summary\"]\n",
    "\n",
    "train_sub_section   = [\"Ensemble Model\", \"LSTM\", \"BERT\"]\n",
    "me_sub_section      = [\"Model Performance\", \"Model Interpretability\"]\n",
    "\n",
    "accordions = OrderedDict()\n",
    "accordions[\"** Loading **\"] = widgets.Accordion(children=[widgets.Output() for section in loading_section])\n",
    "[accordions[\"** Loading **\"].set_title(i, section) for i, section in enumerate(loading_section)]\n",
    "\n",
    "for section in sections:\n",
    "    if section == \"Train\":\n",
    "        accordions[section] = widgets.Accordion(children=[widgets.Output() for sub_section in train_sub_section])\n",
    "        [accordions[section].set_title(i, sub_section) for i, sub_section in enumerate(train_sub_section)]\n",
    "    else:\n",
    "        accordions[section] = widgets.Accordion(children=[widgets.Output() for sub_section in me_sub_section])\n",
    "        [accordions[section].set_title(i, sub_section) for i, sub_section in enumerate(me_sub_section)]\n",
    "        \n",
    "accordions[\"** Conclusion **\"] = widgets.Accordion(children=[widgets.Output() for section in conclusion_section])\n",
    "[accordions[\"** Conclusion **\"].set_title(i, section) for i, section in enumerate(conclusion_section)]\n",
    "        \n",
    "widget_fields = widgets.Tab(children=[accordions[t] for t in accordions])\n",
    "[widget_fields.set_title(i, sub) for i, sub in enumerate(accordions.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c565b310cc03408a959237e1c6c14674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Accordion(children=(Output(), Output()), titles=('Prepare Model Data', 'Data Understanding')), Aâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widget_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train = Train(target_var=\"sentiment\", predictives=\"reviews\", suffix=\"\")\n",
    "self = train\n",
    "\n",
    "# model = Model(m=CLASSFICATION_ALGORITHMS[\"LGBMC_TUNED\"], target_var=\"sentiment\", predictives=\"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "\n",
    "with accordions[\"** Loading **\"].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown(\"<h2> Initiating Modelling Data Preparation ... </h2>\"))\n",
    "    train.get_reviews_data()\n",
    "    train.prepare_model_data(reviews_df=train.data[\"reviews_abt\"])\n",
    "    \n",
    "    \n",
    "with accordions[\"** Loading **\"].children[1]:\n",
    "    clear_output()\n",
    "    display(Markdown(\"<h2> 1. Understand Distribution of Sentiment Across Data ... </h2>\"))\n",
    "    train_count_df = train.data[\"train_df\"][\"sentiment\"].value_counts(normalize=True).reset_index()\n",
    "    train_count_df[\"group\"] = \"train\"\n",
    "    test_count_df = train.data[\"test_df\"][\"sentiment\"].value_counts(normalize=True).reset_index()\n",
    "    test_count_df[\"group\"] = \"test\"\n",
    "    val_count_df = train.data[\"val_df\"][\"sentiment\"].value_counts(normalize=True).reset_index()\n",
    "    val_count_df[\"group\"] = \"val\"\n",
    "    sentiment_count_df = pd.concat([train_count_df, test_count_df, val_count_df], axis=0)\n",
    "    sentiment_count_df[\"proportion\"] = round(sentiment_count_df[\"proportion\"], 3)\n",
    "    display(train.vertical_bar_plot(df=sentiment_count_df, \n",
    "                                    xvar=\"sentiment\", \n",
    "                                    yvar=\"proportion\", \n",
    "                                    hue=\"group\", \n",
    "                                    title=\"Distribution of Sentiments Across Train-Test-Validation Data\"))\n",
    "    \n",
    "    display(Markdown(\"<h2> 2. Understand Tokens Length of Each Reviews ... </h2>\"))\n",
    "    # token_lens = []\n",
    "    # for txt in train.data[\"train_df\"].reviews:\n",
    "    #     tokens = train.tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    #     token_lens.append(len(tokens))\n",
    "    # display(train.tokens_lens_plot(xvar=token_lens, title=\"Length of Tokens of Reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train.train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "1. BERT\n",
    "2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from ignite.metrics import Accuracy, Precision, Recall, Fbeta\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"review_text\": review,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"targets\": torch.tensor(target, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(self, df, tokenizer, max_len, batch_size):\n",
    "    ds = ReviewDataset(\n",
    "        reviews=df[\"reviews\"].to_numpy(), \n",
    "        targets=df[\"sentiment\"].to_numpy(), \n",
    "        tokenizer=tokenizer, \n",
    "        max_len=max_len\n",
    "        )\n",
    "    \n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "# Lets load pre-trained Distill BertTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5)\n",
    "total_steps = len(train.train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n",
    "\n",
    "  model = model.train()    # tells your model that we are training\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    loss, logits = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      labels = targets\n",
    "    )\n",
    "    \n",
    "    # logits = classification scores befroe softmax\n",
    "    # loss = classification loss\n",
    "    \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = targets.to('cpu').numpy()\n",
    "\n",
    "    preds = np.argmax(logits, axis=1).flatten()   #returns indices of maximum logit\n",
    "    targ = label_ids.flatten()\n",
    "\n",
    "    correct_predictions += np.sum(preds == targ)\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()   # performs backpropagation(computes derivates of loss w.r.t to parameters)\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #clipping gradients so they dont explode\n",
    "    optimizer.step()       #After gradients are computed by loss.backward() this makes the optimizer iterate over all parameters it is supposed to update and use internally #stored grad to update their values\n",
    "    scheduler.step()    # this will make sure learning rate changes. If we dont provide this learning rate stays at initial value\n",
    "    optimizer.zero_grad()     # clears old gradients from last step\n",
    "\n",
    "  return correct_predictions / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss logits\n"
     ]
    }
   ],
   "source": [
    "for d in train.train_data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    loss, logits = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      labels = targets\n",
    "    )\n",
    "    \n",
    "    print(loss, logits)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_acc, train_loss \u001b[39m=\u001b[39m train_epoch(model, train\u001b[39m.\u001b[39;49mtrain_data_loader, optimizer, device, scheduler, \u001b[39mlen\u001b[39;49m(train\u001b[39m.\u001b[39;49mdata[\u001b[39m\"\u001b[39;49m\u001b[39mtrain_df\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[35], line 21\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m     12\u001b[0m loss, logits \u001b[39m=\u001b[39m model(\n\u001b[0;32m     13\u001b[0m   input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m     14\u001b[0m   attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m     15\u001b[0m   labels \u001b[39m=\u001b[39m targets\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[39m#logits = classification scores befroe softmax\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m#loss = classification loss\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     22\u001b[0m label_ids \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     24\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mflatten()   \u001b[39m#returns indices of maximum logit\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = train_epoch(model, train.train_data_loader, optimizer, device, scheduler, len(train.data[\"train_df\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, device, n_examples):\n",
    "  \n",
    "  model = model.eval()   # tells model we are in validation mode\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      loss, logits = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        labels = targets\n",
    "      )\n",
    "      \n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = targets.to('cpu').numpy()\n",
    "\n",
    "      preds = np.argmax(logits, axis=1).flatten()\n",
    "      targ = label_ids.flatten()\n",
    "\n",
    "      correct_predictions += np.sum(preds == targ)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:12\u001b[0m\n",
      "Cell \u001b[1;32mIn[35], line 21\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m     12\u001b[0m loss, logits \u001b[39m=\u001b[39m model(\n\u001b[0;32m     13\u001b[0m   input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m     14\u001b[0m   attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m     15\u001b[0m   labels \u001b[39m=\u001b[39m targets\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[39m#logits = classification scores befroe softmax\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m#loss = classification loss\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     22\u001b[0m label_ids \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     24\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mflatten()   \u001b[39m#returns indices of maximum logit\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# standard block\n",
    "# used accuracy as metric here\n",
    "history = defaultdict(list)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(model, train.train_data_loader, optimizer, device, scheduler, len(train.data[\"train_df\"]))\n",
    "\n",
    "  print(f'Train loss {train_loss} Accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(model, train.valid_data_loader, device, len(df_valid))\n",
    "\n",
    "  print(f'Val   loss {val_loss} Accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_acc:\n",
    "    torch.save(model.state_dict(), 'best_model_state_a5.bin')\n",
    "    best_acc = val_acc\n",
    "\n",
    "# We are storing state of best model indicated by highest validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "     \n",
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "      )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class_names = train.data[\"train_df\"][\"sentiment\"].unique()\n",
    "\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n"
     ]
    }
   ],
   "source": [
    "input_ids = data[\"input_ids\"].to(device)\n",
    "attention_mask = data[\"attention_mask\"].to(device)\n",
    "\n",
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model(input_ids, attention_mask)\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36mSentimentClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m---> 10\u001b[0m   _, pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m     11\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m     12\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask\n\u001b[0;32m     13\u001b[0m   )\n\u001b[0;32m     14\u001b[0m   output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop(pooled_output)\n\u001b[0;32m     15\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(output)\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    496\u001b[0m         hidden_states,\n\u001b[0;32m    497\u001b[0m         attention_mask,\n\u001b[0;32m    498\u001b[0m         head_mask,\n\u001b[0;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    426\u001b[0m         hidden_states,\n\u001b[0;32m    427\u001b[0m         attention_mask,\n\u001b[0;32m    428\u001b[0m         head_mask,\n\u001b[0;32m    429\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    430\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    431\u001b[0m         past_key_value,\n\u001b[0;32m    432\u001b[0m         output_attentions,\n\u001b[0;32m    433\u001b[0m     )\n\u001b[0;32m    434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:284\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    275\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    276\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    283\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 284\u001b[0m     mixed_query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(hidden_states)\n\u001b[0;32m    286\u001b[0m     \u001b[39m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[39m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     is_cross_attention \u001b[39m=\u001b[39m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = (\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "    \n",
    "    losses = []\n",
    "    correct_positions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        _, pred = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds=targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clips_grad_norm(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optmizer.zero_grad()\n",
    "        \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "model = LSTMClassifier(no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5)\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 5\n",
    "epochs = 5\n",
    "valid_loss_fn = np.Inf\n",
    "epoch_tr_loss, epoch_vl_loss = [], []\n",
    "epoch_tr_acc, epoch_vl_acc = [], []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    h = model.init_hidden_size(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # # Creating new variables for the hidden state, otherwise backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        \n",
    "        # # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train.losses.append(loss.item())\n",
    "        \n",
    "        accuracy = acc(output, labels)\n",
    "        train_acc += accuracy\n",
    "        \n",
    "        # # clip_norm_grad helps prevent the exploding gradient problem in RNNs/LSTMs\n",
    "        nn.utils.clip_norm_grad(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "    val_h = model.init_hidden_size(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in valid_loader:\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output, val_h = model(inputs, val_h)\n",
    "        val_loss = criterion(output.squeeze(), labels.float())\n",
    "        \n",
    "        val_losses.append(val_loss.item())\n",
    "        accuracy = acc(output, labels)\n",
    "        val_acc += accuracy\n",
    "        \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc / len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc / len(valid_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}\")\n",
    "    print(f\"train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}\")\n",
    "    \n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), \"../working/state_dict.pt\")\n",
    "        print(\"Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...\".format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(35*\"==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in train.data[\"train_df\"].reviews:\n",
    "    tokens = tokenizer.encode(txt, max_length=512)\n",
    "    token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plot(xvar, title=None):\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    sns.distplot(x=xvar, ax=ax)\n",
    "    ax.set_title(title, fontsize=12, weight=\"bold\")\n",
    "    ax.set_ylabel(\"Density\", fontsize=10)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "image/png": {
       "height": 378,
       "width": 872
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distribution_plot(xvar=token_lens, title=\"Length of Tokens of Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review, target, tokenizer, max_len):\n",
    "        self.review = review\n",
    "        self.target = target\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.review)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.review[item])\n",
    "        \n",
    "        encoding = tokenizer.encode_plus(\n",
    "            review,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"],\n",
    "            \"attention_mask\": encoding[\"attention_mask\"],\n",
    "            \"targets\": torch.tensor(self.target[item], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(example, tokenizer, max_length=256):\n",
    "    tokens = tokenizer(example[\"reviews\"])[:max_length]\n",
    "    length = len(tokens)\n",
    "    \n",
    "    return {\"tokens\": tokens, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  initiate English tokenizer from ...\n",
      "  creating Data Dictionary Object...\n",
      "    > train data\n",
      "    > test data\n",
      "    > validation data\n"
     ]
    }
   ],
   "source": [
    "self.logger.info(\"  initiate English tokenizer from ...\")\n",
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "\n",
    "self.logger.info(\"  creating Data Dictionary Object...\")\n",
    "self.logger.info(\"    > train data\")\n",
    "train_dict = train_df[[\"reviews\", \"sentiment\"]].to_dict(orient=\"list\")\n",
    "train_data = Dataset.from_dict(train_dict)\n",
    "\n",
    "self.logger.info(\"    > test data\")\n",
    "test_dict = test_df[[\"reviews\", \"sentiment\"]].to_dict(orient=\"list\")\n",
    "test_data = Dataset.from_dict(test_dict)\n",
    "\n",
    "self.logger.info(\"    > validation data\")\n",
    "val_dict = val_df[[\"reviews\", \"sentiment\"]].to_dict(orient=\"list\")\n",
    "val_data = Dataset.from_dict(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  creating tokens & length of tokens info...\n",
      "    > train data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    > test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    > validation data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 128\n",
    "\n",
    "self.logger.info(\"  creating tokens & length of tokens info...\")\n",
    "self.logger.info(\"    > train data\")\n",
    "train_data = train_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})\n",
    "\n",
    "self.logger.info(\"    > test data\")\n",
    "test_data = test_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})\n",
    "\n",
    "self.logger.info(\"    > validation data\")\n",
    "val_data = val_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 5\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(train_data[\"tokens\"],\n",
    "                                                  min_freq=min_freq,\n",
    "                                                  specials=special_tokens)\n",
    "\n",
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]\n",
    "vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_data(example, vocab):\n",
    "    ids = [vocab[token] for token in example[\"tokens\"]]\n",
    "    \n",
    "    return {\"ids\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  numericalize text data...\n",
      "    > train data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    > test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    > validation data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "self.logger.info(\"  numericalize text data...\")\n",
    "self.logger.info(\"    > train data\")\n",
    "train_data = train_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\n",
    "self.logger.info(\"    > test data\")\n",
    "test_data = test_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\n",
    "self.logger.info(\"    > validation data\")\n",
    "val_data = val_data.map(numericalize_data, fn_kwargs={'vocab': vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  transform data into Pytorch format...\n",
      "    > train data\n",
      "    > test data\n",
      "    > validation data\n"
     ]
    }
   ],
   "source": [
    "self.logger.info(\"  transform data into Pytorch format...\")\n",
    "self.logger.info(\"    > train data\")\n",
    "train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"sentiment\", \"length\"])\n",
    "self.logger.info(\"    > test data\")\n",
    "test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"sentiment\", \"length\"])\n",
    "self.logger.info(\"    > validation data\")\n",
    "val_data = val_data.with_format(type=\"torch\", columns=[\"ids\", \"sentiment\", \"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.DataFrame.from_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121612, 5)\n",
      "(38005, 5)\n",
      "(30404, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='imdb_data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f, encoding='utf8') as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_imdb_data()\n",
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    \"\"\"Prepare training and test sets from IMDb movie reviews.\"\"\"\n",
    "    \n",
    "    #Combine positive and negative reviews and labels\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    #Shuffle reviews and corresponding labels within training and test sets\n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    # Return a unified training data, test data, training labels, test labets\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cache_dir = os.path.join(\"cache\", \"sentiment_analysis\")  # where to store cache files\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "\n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "    \n",
    "    # If cache is missing, then do the heavy lifting\n",
    "    if cache_data is None:\n",
    "        # Preprocess training and test data to obtain words for each review\n",
    "        #words_train = list(map(review_to_words, data_train))\n",
    "        #words_test = list(map(review_to_words, data_test))\n",
    "        words_train = [review_to_words(review) for review in data_train]\n",
    "        words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "        # Write to cache file for future runs\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                              labels_train=labels_train, labels_test=labels_test)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "    \n",
    "    return words_train, words_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote preprocessed data to cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = preprocess_data(train_dict[\"reviews\"], test_dict[\"reviews\"], \n",
    "                                                   train_dict[\"sentiment\"], test_dict[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    # TODO: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    #       sentence is a list of words.\n",
    "    \n",
    "    word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    \n",
    "    for review in data:\n",
    "        for word in review:\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "    \n",
    "    # TODO: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    #       sorted_words[-1] is the least frequently appearing word.\n",
    "    \n",
    "    sorted_words = [k for k, v in sorted(word_count.items(), key=lambda item: item[1], reverse=True)]\n",
    "    \n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
    "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/pytorch' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_dict = build_dict(train_dict[\"reviews\"])\n",
    "\n",
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of 51th review:  500\n",
      "All values in scope:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2211,  312, 3761, 1438, 2635, 2337,  490,  316, 2014,   38,    1,\n",
       "       1438,   52,    1, 1123,  685,  115, 2831,   95,  888,   39,    4,\n",
       "       3761,   90, 2211,  121,  804,  177, 1006, 1258,   27,  173,   84,\n",
       "        296,    1,   31,   79,  176,  182, 3916, 2584,  235,  623,  437,\n",
       "        867, 1448,    4,  285,  136,  579,  115,   27, 1566,  246,  563,\n",
       "       1306,   11,   31,    4,   76,  227,    1,  214, 1435, 2910,   72,\n",
       "        168,   20,    2,  139,   93,  326,   33,   71,    1,    5, 1269,\n",
       "       2472,  872,  237,   29,   11,  313,    1, 2814,  147,   84,    6,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Lenght of 51th review: \", len(train_X[50]))\n",
    "print(\"All values in scope: \", len([1 for num in train_X[50] if num >=0 and num <= 4998]) == len(train_X[50]))\n",
    "train_X[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>55</td>\n",
       "      <td>287</td>\n",
       "      <td>229</td>\n",
       "      <td>1267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4095</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>3219</td>\n",
       "      <td>3007</td>\n",
       "      <td>954</td>\n",
       "      <td>2032</td>\n",
       "      <td>508</td>\n",
       "      <td>1246</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>514</td>\n",
       "      <td>348</td>\n",
       "      <td>233</td>\n",
       "      <td>184</td>\n",
       "      <td>16</td>\n",
       "      <td>186</td>\n",
       "      <td>580</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1647</td>\n",
       "      <td>55</td>\n",
       "      <td>3731</td>\n",
       "      <td>243</td>\n",
       "      <td>819</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>536</td>\n",
       "      <td>643</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>243</td>\n",
       "      <td>694</td>\n",
       "      <td>411</td>\n",
       "      <td>335</td>\n",
       "      <td>2744</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>719</td>\n",
       "      <td>341</td>\n",
       "      <td>2224</td>\n",
       "      <td>2101</td>\n",
       "      <td>531</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>224</td>\n",
       "      <td>403</td>\n",
       "      <td>4365</td>\n",
       "      <td>11</td>\n",
       "      <td>1886</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>849</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>506</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>659</td>\n",
       "      <td>20</td>\n",
       "      <td>3631</td>\n",
       "      <td>241</td>\n",
       "      <td>2239</td>\n",
       "      <td>1</td>\n",
       "      <td>666</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    0    0    1     2     3     4     5     6     7    ...  490  491   \n",
       "0        0   79   55  287   229  1267     1     1  4095     1  ...    0    0  \\\n",
       "1        1  126    1   76  3219  3007   954  2032   508  1246  ...    0    0   \n",
       "2        0  225    2  514   348   233   184    16   186   580  ...    0    0   \n",
       "3        0  135    3   87     1  1647    55  3731   243   819  ...    0    0   \n",
       "4        0  189   12   91   536   643    10     1     3   150  ...    0    0   \n",
       "...    ...  ...  ...  ...   ...   ...   ...   ...   ...   ...  ...  ...  ...   \n",
       "24995    0   82  243  694   411   335  2744    97    95    63  ...    0    0   \n",
       "24996    1   44   37  719   341  2224  2101   531    30    17  ...    0    0   \n",
       "24997    0  134  224  403  4365    11  1886     2    49    37  ...    0    0   \n",
       "24998    1  166   29   20   849    59    12    28   506   197  ...    0    0   \n",
       "24999    1  354  659   20  3631   241  2239     1   666     4  ...    0    0   \n",
       "\n",
       "       492  493  494  495  496  497  498  499  \n",
       "0        0    0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "24995    0    0    0    0    0    0    0    0  \n",
       "24996    0    0    0    0    0    0    0    0  \n",
       "24997    0    0    0    0    0    0    0    0  \n",
       "24998    0    0    0    0    0    0    0    0  \n",
       "24999    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[25000 rows x 502 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_X, transformed_train_train_X_len = convert_and_pad_data(word_dict, train_dict[\"reviews\"])\n",
    "transformed_test_X, transformed_test_X_len = convert_and_pad_data(word_dict, test_dict[\"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of 51th review:  500\n",
      "All values in scope:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4,  3, 10, 10,  7, 21, 12, 18,  2,  7, 16, 22, 10,  3,  8,  8,  2,\n",
       "       21,  6,  6, 26,  2, 21, 15,  4,  8, 14, 11,  3, 10,  2,  5, 22, 22,\n",
       "        3,  5, 10,  2, 16,  3, 10,  3, 12, 18,  2,  4, 10, 18,  2, 22, 12,\n",
       "        5,  4, 11,  2, 14,  5,  8, 11,  2, 14,  6, 20,  2, 22, 10,  3,  4,\n",
       "        4, 18,  2, 14,  6, 12, 12,  3, 14,  4,  3, 13,  2, 22,  6,  3, 16,\n",
       "        2, 22, 12,  5,  4, 11,  2, 22, 12,  5,  4, 11,  2, 16, 18,  4, 11,\n",
       "        2, 19, 15,  5, 10,  5,  9,  4,  3,  3,  2,  8,  5, 12,  3,  2, 13,\n",
       "        7,  8, 12,  7, 26,  3,  2, 17,  5, 14,  4,  2,  4,  3,  9, 13,  2,\n",
       "       15,  8,  3,  2, 22, 10,  7, 16,  5, 10, 18,  2,  8,  6, 15, 10, 14,\n",
       "        3,  2, 13,  3,  8, 22,  7,  4,  3,  2, 17,  5, 14,  4,  2, 16,  5,\n",
       "       43,  6, 10,  2, 22, 12,  5, 18,  3, 10,  2, 12,  7, 17,  3,  2,  4,\n",
       "        3, 13,  2, 11, 15, 19, 11,  3,  8,  2,  5, 15, 10,  3, 12,  7,  5,\n",
       "        2, 22, 12,  5,  4, 11,  2,  5, 12,  7, 24,  3,  2,  5, 22, 22,  3,\n",
       "        5, 10,  2,  8,  3, 14,  6,  9, 13,  5, 10, 18,  2,  4,  3, 10,  4,\n",
       "        7,  5, 10, 18,  2,  8,  6, 15, 10, 14,  3,  2, 14,  6,  9,  8,  4,\n",
       "       10,  5,  7,  9,  4,  2, 22, 12,  5,  4, 11,  2,  3,  8,  4,  5,  4,\n",
       "        3,  2,  3,  8,  8,  3,  9,  4,  7,  5, 12, 12, 18,  2,  4,  3, 13,\n",
       "        2, 11, 15, 19, 11,  3,  8,  2,  8,  7,  8,  4,  3, 10,  2,  6, 12,\n",
       "       20, 18,  9,  2,  3,  9, 43,  6, 18,  2, 21,  6,  6, 26,  2, 10,  5,\n",
       "        9, 26,  2,  6, 22,  7,  9,  7,  6,  9,  2, 14,  5, 10, 12,  2, 10,\n",
       "        6, 12, 12, 18,  8,  6,  9,  2,  5, 16,  3, 10,  7, 14,  5,  2,  7,\n",
       "        8,  7,  2, 16,  6,  9,  3, 18,  2, 19, 10,  5, 21,  2,  3, 13,  7,\n",
       "        4,  6, 10,  2,  5, 19,  3,  9,  4,  2, 22, 15, 21, 12,  7,  8, 11,\n",
       "        3, 10,  2,  5, 15,  4, 11,  6, 10,  2,  3, 16, 21,  5, 10,  5,  8,\n",
       "        8,  2, 22,  7,  3, 14,  3,  2,  4, 10,  7, 22,  3,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Lenght of 51th review: \", len(transformed_train_X[50]))\n",
    "print(\"All values in scope: \", len([1 for num in transformed_train_X[50] if num >=0 and num <= 4998]) == len(transformed_train_X[50]))\n",
    "transformed_train_X[50]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.word_dict = None\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        x = x.t()\n",
    "        lengths = x[0,:]\n",
    "        reviews = x[1:,:]\n",
    "        embeds = self.embedding(reviews)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.dense(lstm_out)\n",
    "        out = out[lengths - 1, range(len(lengths))]\n",
    "        return self.sig(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            model.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            ps = model(batch_X)\n",
    "            loss = loss_fn(ps, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "    \n",
    "    model_id = str(datetime.now()).split(\" \")[0].replace(\"-\", \"_\") + \\\n",
    "            str(datetime.now()).split(\" \")[1].split(\".\")[0].replace(\":\", \"_\")\n",
    "    model_path = os.path.join(self.FILES[\"MODEL_DATA_DIR\"], \"lstm_model_{}.pth\".format(model_id))\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train_sample = pd.concat([pd.DataFrame(train_dict[\"sentiment\"]), \n",
    "                                    pd.DataFrame(transformed_train_train_X_len), \n",
    "                                    pd.DataFrame(transformed_train_X)], axis=1)\n",
    "transform_train_sample.columns = [str(i) for i in range(len(transform_train_sample.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "# Build the dataloader\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, BCELoss: 0.6997045278549194\n",
      "Epoch: 2, BCELoss: 0.6906813263893128\n",
      "Epoch: 3, BCELoss: 0.6836840033531189\n",
      "Epoch: 4, BCELoss: 0.6765644550323486\n",
      "Epoch: 5, BCELoss: 0.6684593081474304\n",
      "Epoch: 6, BCELoss: 0.658358097076416\n",
      "Epoch: 7, BCELoss: 0.6447415709495544\n",
      "Epoch: 8, BCELoss: 0.6248663425445556\n",
      "Epoch: 9, BCELoss: 0.5931399941444397\n",
      "Epoch: 10, BCELoss: 0.5539361834526062\n",
      "Epoch: 11, BCELoss: 0.4990801870822906\n",
      "Epoch: 12, BCELoss: 0.44975553154945375\n",
      "Epoch: 13, BCELoss: 0.40791605710983275\n",
      "Epoch: 14, BCELoss: 0.3401987373828888\n",
      "Epoch: 15, BCELoss: 0.3005742937326431\n",
      "Epoch: 16, BCELoss: 0.24265267252922057\n",
      "Epoch: 17, BCELoss: 0.281191948056221\n",
      "Epoch: 18, BCELoss: 0.2682305365800858\n",
      "Epoch: 19, BCELoss: 0.1890871435403824\n",
      "Epoch: 20, BCELoss: 0.22829505801200867\n",
      "Epoch: 21, BCELoss: 0.17231179475784303\n",
      "Epoch: 22, BCELoss: 0.13192037045955657\n",
      "Epoch: 23, BCELoss: 0.13077259063720703\n",
      "Epoch: 24, BCELoss: 0.09353011697530747\n",
      "Epoch: 25, BCELoss: 0.06921389326453209\n",
      "Epoch: 26, BCELoss: 0.06605177223682404\n",
      "Epoch: 27, BCELoss: 0.04624384753406048\n",
      "Epoch: 28, BCELoss: 0.02999134175479412\n",
      "Epoch: 29, BCELoss: 0.021964151039719583\n",
      "Epoch: 30, BCELoss: 0.017538803815841674\n",
      "Epoch: 31, BCELoss: 0.012414730712771415\n",
      "Epoch: 32, BCELoss: 0.009578244294971228\n",
      "Epoch: 33, BCELoss: 0.007176239881664515\n",
      "Epoch: 34, BCELoss: 0.006231950223445892\n",
      "Epoch: 35, BCELoss: 0.005132349347695709\n",
      "Epoch: 36, BCELoss: 0.004375000949949026\n",
      "Epoch: 37, BCELoss: 0.003772731125354767\n",
      "Epoch: 38, BCELoss: 0.0033385366201400756\n",
      "Epoch: 39, BCELoss: 0.0030353303533047437\n",
      "Epoch: 40, BCELoss: 0.0027711969101801514\n",
      "Epoch: 41, BCELoss: 0.0025391281116753815\n",
      "Epoch: 42, BCELoss: 0.0023458136711269617\n",
      "Epoch: 43, BCELoss: 0.0021836627274751663\n",
      "Epoch: 44, BCELoss: 0.002042062790133059\n",
      "Epoch: 45, BCELoss: 0.0019183171447366477\n",
      "Epoch: 46, BCELoss: 0.001807246496900916\n",
      "Epoch: 47, BCELoss: 0.0017073319992050528\n",
      "Epoch: 48, BCELoss: 0.0016170194838196039\n",
      "Epoch: 49, BCELoss: 0.0015339661855250596\n",
      "Epoch: 50, BCELoss: 0.0014579801587387919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(5000, 32, padding_idx=0)\n",
       "  (lstm): LSTM(32, 100)\n",
       "  (dense): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(32, 100, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train(model, train_sample_dl, 50, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "hidden_dim = 100\n",
    "vocab_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters used to construct the model\n",
    "model_id = str(datetime.now()).split(\" \")[0].replace(\"-\", \"_\") + \\\n",
    "            str(datetime.now()).split(\" \")[1].split(\".\")[0].replace(\":\", \"_\")\n",
    "model_info_path = os.path.join(self.FILES[\"MODEL_DATA_DIR\"], \"model_info_{}.pth\".format(model_id))\n",
    "with open(model_info_path, \"wb\") as f:\n",
    "    model_info = {\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"vocab_size\": vocab_size,\n",
    "    }\n",
    "    torch.save(model_info, f)\n",
    "\n",
    "# Save the word_dict\n",
    "word_dict_path = os.path.join(self.FILES[\"MODEL_DATA_DIR\"], \"word_dict_{}.pkl\".format(model_id))\n",
    "with open(word_dict_path, \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)\n",
    "\n",
    "# Save the model parameters\n",
    "model_path = os.path.join(self.FILES[\"MODEL_DATA_DIR\"], \"model_{}.pth\".format(model_id))\n",
    "with open(model_path, \"wb\") as f:\n",
    "    torch.save(model.cpu().state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test_X = pd.concat([pd.DataFrame(transformed_test_X_len), pd.DataFrame(transformed_test_X)], axis=1)\n",
    "transformed_test_X.columns = [str(i) for i in range(len(transformed_test_X.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transformed_test_X\n",
    "rows = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
    "                 dropout_rate, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
    "                            dropout=dropout_rate, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        \n",
    "    def forward(self, ids, length):\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, length, batch_first=True, \n",
    "                                                            enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "\n",
    "        prediction = self.fc(hidden)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300 # 300\n",
    "hidden_dim = 300 # 300\n",
    "output_dim = len(train_data.unique(\"sentiment\"))\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n",
    "             pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 26,772,303 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(77203, 300, padding_idx=1)\n",
       "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=600, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif \"weight\" in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Vectors.__init__() got an unexpected keyword argument 'skiprows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torchtext\\vocab\\vectors.py:230\u001b[0m, in \u001b[0;36mFastText.__init__\u001b[1;34m(self, language, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl_base\u001b[38;5;241m.\u001b[39mformat(language)\n\u001b[0;32m    229\u001b[0m name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28msuper\u001b[39m(FastText, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Vectors.__init__() got an unexpected keyword argument 'skiprows'"
     ]
    }
   ],
   "source": [
    "vectors = torchtext.vocab.FastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                      | 0/1245299 [00:00<?, ?it/s]Skipping token b'2519370' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1245299/1245299 [01:46<00:00, 11747.46it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Vector for token b'southfarthing' has 187 dimensions, but previously read vectors have 300 dimensions. All vectors must have the same number of dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m pretrained_embedding \u001b[38;5;241m=\u001b[39m vectors\u001b[38;5;241m.\u001b[39mget_vecs_by_tokens(vocab\u001b[38;5;241m.\u001b[39mget_itos())\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m pretrained_embedding\n",
      "File \u001b[1;32m~\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torchtext\\vocab\\vectors.py:230\u001b[0m, in \u001b[0;36mFastText.__init__\u001b[1;34m(self, language, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl_base\u001b[38;5;241m.\u001b[39mformat(language)\n\u001b[0;32m    229\u001b[0m name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28msuper\u001b[39m(FastText, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torchtext\\vocab\\vectors.py:59\u001b[0m, in \u001b[0;36mVectors.__init__\u001b[1;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mzero_ \u001b[38;5;28;01mif\u001b[39;00m unk_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unk_init\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\02-Self_Learning\\01-Data_Science\\11-Sentiment_Analysis\\sentiment_venv\\lib\\site-packages\\torchtext\\vocab\\vectors.py:140\u001b[0m, in \u001b[0;36mVectors.cache\u001b[1;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(entries):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector for token \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, but previously \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread vectors have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions. All vectors must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe same number of dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(word, \u001b[38;5;28mlen\u001b[39m(entries), dim)\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(word, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Vector for token b'southfarthing' has 187 dimensions, but previously read vectors have 300 dimensions. All vectors must have the same number of dimensions."
     ]
    }
   ],
   "source": [
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
    "\n",
    "model.embedding.weight.data = pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lr = 5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch, pad_index):\n",
    "    batch_ids = [i[\"ids\"] for i in batch]\n",
    "    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n",
    "    batch_length = [i[\"length\"] for i in batch]\n",
    "    batch_length = torch.stack(batch_length)\n",
    "    batch_label = [i[\"label\"] for i in batch]\n",
    "    batch_label = torch.stack(batch_label)\n",
    "    batch = {\"ids\": batch_ids,\n",
    "             \"length\": batch_length,\n",
    "             \"label\": batch_label}\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "collate = functools.partial(collate, pad_index=pad_index)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, \n",
    "                                               batch_size=batch_size, \n",
    "                                               collate_fn=collate, \n",
    "                                               shuffle=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    for batch in tqdm.tqdm(dataloader, desc='training...', file=sys.stdout):\n",
    "        ids = batch['ids'].to(device)\n",
    "        length = batch['length']\n",
    "        label = batch['label'].to(device)\n",
    "        prediction = model(ids, length)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "\n",
    "    return epoch_losses, epoch_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>book_author</th>\n",
       "      <th>reviews</th>\n",
       "      <th>title</th>\n",
       "      <th>reviews_length</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_encode</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36108</th>\n",
       "      <td>11884</td>\n",
       "      <td>John Cheever</td>\n",
       "      <td>cheever writer page book cheever journal entry...</td>\n",
       "      <td>The Journals</td>\n",
       "      <td>780</td>\n",
       "      <td>4.21</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12639</th>\n",
       "      <td>10631</td>\n",
       "      <td>Sam Walton</td>\n",
       "      <td>mnogie dumaiut chto eto sem uolton otkryl form...</td>\n",
       "      <td>Sam Walton: Made In America</td>\n",
       "      <td>700</td>\n",
       "      <td>4.12</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77088</th>\n",
       "      <td>2735</td>\n",
       "      <td>David Guterson</td>\n",
       "      <td>na een mistige nacht wordt vissersboot van car...</td>\n",
       "      <td>Snow Falling On Cedars</td>\n",
       "      <td>1542</td>\n",
       "      <td>3.85</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178903</th>\n",
       "      <td>9296</td>\n",
       "      <td>Isabel Allende</td>\n",
       "      <td>lmwt l wjwd lh y bnty lns ymwtwn ` ndm ytwyhm ...</td>\n",
       "      <td>Eva Luna</td>\n",
       "      <td>142</td>\n",
       "      <td>3.99</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28456</th>\n",
       "      <td>11494</td>\n",
       "      <td>Saul Bellow</td>\n",
       "      <td>humboldt poet revere eventually ridicule charl...</td>\n",
       "      <td>Humboldt's Gift</td>\n",
       "      <td>2961</td>\n",
       "      <td>3.85</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144598</th>\n",
       "      <td>6661</td>\n",
       "      <td>Lawrence C. Ross</td>\n",
       "      <td>member sorority sigma gamma rho sorority book ...</td>\n",
       "      <td>The Divine Nine: The History of African-Americ...</td>\n",
       "      <td>230</td>\n",
       "      <td>4.06</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158837</th>\n",
       "      <td>7562</td>\n",
       "      <td>Chris Ware</td>\n",
       "      <td>guess like better ware sustain narrative like ...</td>\n",
       "      <td>The Acme Novelty Library</td>\n",
       "      <td>677</td>\n",
       "      <td>4.31</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51512</th>\n",
       "      <td>979</td>\n",
       "      <td>Dan Brown</td>\n",
       "      <td>stand dan brown book interesting hold robert l...</td>\n",
       "      <td>Deception Point</td>\n",
       "      <td>934</td>\n",
       "      <td>3.74</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19267</th>\n",
       "      <td>11017</td>\n",
       "      <td>Charlotte BrontÃ«</td>\n",
       "      <td>year saying jane eyre favorite novel time char...</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>404</td>\n",
       "      <td>4.14</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74356</th>\n",
       "      <td>2571</td>\n",
       "      <td>Wole Soyinka</td>\n",
       "      <td>best thing read state anxiety world today mani...</td>\n",
       "      <td>Climate of Fear: The Quest for Dignity in a De...</td>\n",
       "      <td>162</td>\n",
       "      <td>3.62</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38005 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        page_number       book_author   \n",
       "36108         11884      John Cheever  \\\n",
       "12639         10631        Sam Walton   \n",
       "77088          2735    David Guterson   \n",
       "178903         9296    Isabel Allende   \n",
       "28456         11494       Saul Bellow   \n",
       "...             ...               ...   \n",
       "144598         6661  Lawrence C. Ross   \n",
       "158837         7562        Chris Ware   \n",
       "51512           979         Dan Brown   \n",
       "19267         11017  Charlotte BrontÃ«   \n",
       "74356          2571      Wole Soyinka   \n",
       "\n",
       "                                                  reviews   \n",
       "36108   cheever writer page book cheever journal entry...  \\\n",
       "12639   mnogie dumaiut chto eto sem uolton otkryl form...   \n",
       "77088   na een mistige nacht wordt vissersboot van car...   \n",
       "178903  lmwt l wjwd lh y bnty lns ymwtwn ` ndm ytwyhm ...   \n",
       "28456   humboldt poet revere eventually ridicule charl...   \n",
       "...                                                   ...   \n",
       "144598  member sorority sigma gamma rho sorority book ...   \n",
       "158837  guess like better ware sustain narrative like ...   \n",
       "51512   stand dan brown book interesting hold robert l...   \n",
       "19267   year saying jane eyre favorite novel time char...   \n",
       "74356   best thing read state anxiety world today mani...   \n",
       "\n",
       "                                                    title  reviews_length   \n",
       "36108                                        The Journals             780  \\\n",
       "12639                         Sam Walton: Made In America             700   \n",
       "77088                              Snow Falling On Cedars            1542   \n",
       "178903                                           Eva Luna             142   \n",
       "28456                                     Humboldt's Gift            2961   \n",
       "...                                                   ...             ...   \n",
       "144598  The Divine Nine: The History of African-Americ...             230   \n",
       "158837                           The Acme Novelty Library             677   \n",
       "51512                                     Deception Point             934   \n",
       "19267                                           Jane Eyre             404   \n",
       "74356   Climate of Fear: The Quest for Dignity in a De...             162   \n",
       "\n",
       "        rating rating_encode  sentiment  \n",
       "36108     4.21      positive          0  \n",
       "12639     4.12      positive          0  \n",
       "77088     3.85       neutral          1  \n",
       "178903    3.99       neutral          1  \n",
       "28456     3.85       neutral          1  \n",
       "...        ...           ...        ...  \n",
       "144598    4.06      positive          0  \n",
       "158837    4.31      positive          0  \n",
       "51512     3.74       neutral          1  \n",
       "19267     4.14      positive          0  \n",
       "74356     3.62       neutral          1  \n",
       "\n",
       "[38005 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n",
    "            ids = batch['ids'].to(device)\n",
    "            length = batch['length']\n",
    "            label = batch['label'].to(device)\n",
    "            prediction = model(ids, length)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "\n",
    "    return epoch_losses, epoch_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(valid_dataloader, model, criterion, device)\n",
    "\n",
    "    train_losses.extend(train_loss)\n",
    "    train_accs.extend(train_acc)\n",
    "    valid_losses.extend(valid_loss)\n",
    "    valid_accs.extend(valid_acc)\n",
    "    \n",
    "    epoch_train_loss = np.mean(train_loss)\n",
    "    epoch_train_acc = np.mean(train_acc)\n",
    "    epoch_valid_loss = np.mean(valid_loss)\n",
    "    epoch_valid_acc = np.mean(valid_acc)\n",
    "    \n",
    "    if epoch_valid_loss < best_valid_loss:\n",
    "        best_valid_loss = epoch_valid_loss\n",
    "        torch.save(model.state_dict(), 'lstm.pt')\n",
    "    \n",
    "    print(f'epoch: {epoch+1}')\n",
    "    print(f'train_loss: {epoch_train_loss:.3f}, train_acc: {epoch_train_acc:.3f}')\n",
    "    print(f'valid_loss: {epoch_valid_loss:.3f}, valid_acc: {epoch_valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(train_losses, label='train loss')\n",
    "ax.plot(valid_losses, label='valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(train_accs, label='train accuracy')\n",
    "ax.plot(valid_accs, label='valid accuracy')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('lstm.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n",
    "\n",
    "epoch_test_loss = np.mean(test_loss)\n",
    "epoch_test_acc = np.mean(test_acc)\n",
    "\n",
    "print(f'test_loss: {epoch_test_loss:.3f}, test_acc: {epoch_test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, vocab, device):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = [vocab[t] for t in tokens]\n",
    "    length = torch.LongTensor([len(ids)])\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor, length).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This app is bad!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
