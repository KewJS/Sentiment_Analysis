{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e313aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML, clear_output, display_html\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from src.train import Train\n",
    "from src.train.ensemble import Model\n",
    "from src.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67546c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1153d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSFICATION_ALGORITHMS = dict(\n",
    "    XGBC = dict(alg=XGBClassifier, args=dict(random_state=42, use_label_encoder=False, early_stopping=5, \n",
    "                                             enable_categorical=True,\n",
    "                                             eval_metric=\"aucpr\",\n",
    "                                             sample_weight=None\n",
    "                                            )),\n",
    "    \n",
    "    LGBMC = dict(alg=LGBMClassifier, args=dict(early_stopping=5,\n",
    "                                               class_weight=None,\n",
    "                                              )),\n",
    "    \n",
    "    XGBC_TUNED = dict(alg=XGBClassifier, args=dict(random_state=42, use_label_encoder=False, early_stopping=5,\n",
    "                                                   enable_categorical=True,\n",
    "                                                   eval_metric=\"aucpr\",\n",
    "                                                   sample_weight=None),\n",
    "                      param_grid = {\n",
    "#                           \"scale_pos_weight\": [0.5, 1.0, 2.0, 4.5],\n",
    "                          \"n_estimators\": [25, 50, 100],\n",
    "                          \"max_delta_step\": [0, 1.0, 3.0, 5.0],\n",
    "                          \"max_bin\": [2, 5, 7, 10],\n",
    "                          \"max_depth\": [5, 6, 8, None],\n",
    "                          \"gamma\": [0.5, 1.5, 2.5, 4],\n",
    "                          \"min_child_weight\": [0.05, 0.01, 1, 2],\n",
    "                          \"eta\": [0.005, 0.01, 0.05],\n",
    "                          \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "#                           \"subsample\": [0.5, 0.7],\n",
    "#                           \"colsample_bytree\": [0.5, 0.7],\n",
    "#                           \"colsample_bylevel\": [0.5, 0.7],\n",
    "#                           \"colsample_bynode\": [0.5, 0.7],\n",
    "#                           \"alpha\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"lambda\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"reg_alpha\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"reg_lambda\": [0.5, 0.7, 0.9, 1.3],\n",
    "                      }\n",
    "                     ),\n",
    "    \n",
    "    LGBMC_TUNED = dict(alg=LGBMClassifier, args=dict(early_stopping=5,\n",
    "                                                    class_weight=None,\n",
    "                                                   ),\n",
    "                      param_grid = {\n",
    "#                           \"scale_pos_weight\": [0.5, 1.0, 2.0, 4.5],\n",
    "                          \"n_estimators\": [25, 50, 100],\n",
    "                          \"max_delta_step\": [0, 3, 6, 9],\n",
    "                          \"max_bin\": [2, 5, 7, 10],\n",
    "                          \"max_depth\": [5, 6, 8, None],\n",
    "                          \"gamma\": [0.5, 1.5, 2.5, 4],\n",
    "                          \"min_child_weight\": [0.05, 0.01, 1, 2],\n",
    "                          \"min_sum_hessian_in_leaf\": [0.001, 0.005, 0.01, 0.05],\n",
    "                          \"min_data_in_leaf\": [60, 120, 240],\n",
    "                          \"eta\": [0.005, 0.01, 0.05],\n",
    "                          \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "#                           \"lambda_l1\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"lambda_l2\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"reg_alpha\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"reg_lambda\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"path_smooth\": [0.5, 0.7, 0.9, 1.3],\n",
    "#                           \"bagging_fraction\": [0.5, 0.7, 0.8],\n",
    "#                           \"feature_fraction\": [0.5, 0.7, 0.8],\n",
    "#                           \"colsample_bytree\": [0.5, 0.7],\n",
    "                      }\n",
    "                     ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4da7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2>Book Reviews Sentiment Analysis</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"<h2>Book Reviews Sentiment Analysis</h2>\"))\n",
    "loading_section       = [\"Prepare Model Data\"]\n",
    "sections              = [\"Ensemble Model\", \"LSTM\", \"BERT\"]\n",
    "conclusion_section    = [\"Summary\"]\n",
    "\n",
    "train_sub_section   = [\"Train\", \"Model Evaluation\", \"Model Interpretation\"]\n",
    "me_sub_section      = [\"Best Model\", \"Interpretability\"]\n",
    "\n",
    "accordions = OrderedDict()\n",
    "accordions[\"** Loading **\"] = widgets.Accordion(children=[widgets.Output() for section in loading_section])\n",
    "[accordions[\"** Loading **\"].set_title(i, section) for i, section in enumerate(loading_section)]\n",
    "\n",
    "for section in sections:\n",
    "    if (section == \"Ensemble Model\") or (section == \"LSTM\") or (section == \"BERT\") :\n",
    "        accordions[section] = widgets.Accordion(children=[widgets.Output() for sub_section in train_sub_section])\n",
    "        [accordions[section].set_title(i, sub_section) for i, sub_section in enumerate(train_sub_section)]\n",
    "    else:\n",
    "        accordions[section] = widgets.Accordion(children=[widgets.Output() for sub_section in me_sub_section])\n",
    "        [accordions[section].set_title(i, sub_section) for i, sub_section in enumerate(me_sub_section)]\n",
    "        \n",
    "accordions[\"** Conclusion **\"] = widgets.Accordion(children=[widgets.Output() for section in conclusion_section])\n",
    "[accordions[\"** Conclusion **\"].set_title(i, section) for i, section in enumerate(conclusion_section)]\n",
    "        \n",
    "widget_fields = widgets.Tab(children=[accordions[t] for t in accordions])\n",
    "[widget_fields.set_title(i, sub) for i, sub in enumerate(accordions.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1e074c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c52062ab5d542719cc79b9320ea65c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Accordion(children=(Output(),), titles=('Prepare Model Data',)), Accordion(children=(Output(), Oâ€¦"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widget_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4a3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Train(target_var=\"sentiment\", predictives=\"reviews\", suffix=\"\")\n",
    "self = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9075fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "\n",
    "with accordions[\"** Loading **\"].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown(\"<h2> Initiating Modelling Data Preparation ... </h2>\"))\n",
    "    train.prepare_model_data()\n",
    "\n",
    "#     display(train.histogram_plot(xvar=train.token_lens, \n",
    "#                                  xlabel=\"Token count: Most of the reviews seem to contain less than 128 tokens, to be on the safe side and choose a maximum length of 160.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4396ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "section = \"Ensemble Model\"\n",
    "algorithms = [\"LGBMC\", \"LGBMC_TUNED\"]\n",
    "\n",
    "with accordions[section].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown(r\"<h2> Initiate Training of Ensemble Models on Sentiment Analysis: </h2>\"))\n",
    "    train.run(data=train.data[\"reviews_abt\"], algorithms=algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd659b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "section = \"Ensemble Model\"\n",
    "algorithms = [\"LGBMC\", \"LGBMC_TUNED\"]\n",
    "\n",
    "with accordions[section].children[1]:\n",
    "    clear_output()\n",
    "    display(Markdown(r\"<h2> Evaluate Model: </h2>\"))\n",
    "    display(train.data[\"metrics_df\"])\n",
    "    \n",
    "    for alg in train.models:\n",
    "        display(Markdown(r\"<h4> Model: {} </h4>\".format(alg)))\n",
    "        display(train.confusion_matrix_plot(cf_matrix=train.models[alg][\"test_metrics\"][\"CM\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6878f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "section = \"Ensemble Model\"\n",
    "algorithms = [\"LGBMC\", \"LGBMC_TUNED\"]\n",
    "\n",
    "with accordions[section].children[2]:\n",
    "    clear_output()\n",
    "    display(Markdown(r\"<h2> Evaluate Model: </h2>\"))\n",
    "    display(train.data[\"metrics_df\"])\n",
    "    \n",
    "    for alg in train.models:\n",
    "        display(Markdown(r\"<h4> Model: {} </h4>\".format(alg)))\n",
    "        display(train.confusion_matrix_plot(cf_matrix=train.models[\"LGBMC_TUNED\"][\"test_metrics\"][\"CM\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58acd5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_venv",
   "language": "python",
   "name": "sentiment_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
